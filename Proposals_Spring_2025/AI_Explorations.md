# Comprehensive AI Explorations for Undergraduate Computer Science Students

## 1. Project Overview

**Project Title**  
Comprehensive AI Explorations for Undergraduate Computer Science Students

**Project Purpose**  
Provide a structured, hands-on learning program for freshman-level Computer Science students to explore a variety of AI concepts, tools, and best practices. Each task is distinct yet contributes to building a well-rounded foundation in AI research and development.

---

## 2. Objectives

1. **Tool Mastery**  
   Introduce and practice using modern development tools (e.g., GitHub Copilot, Visual Studio Code) and AI APIs (OpenAI, others).  
2. **Foundational Understanding**  
   Learn core machine learning and AI concepts, including data handling, model training, and performance evaluation.  
3. **Practical Application**  
   Develop tangible projects in areas such as chatbots, generative AI, and reinforcement learning.  
4. **Ethical and Responsible AI**  
   Understand AI fairness and bias detection, fostering responsible development practices.  
5. **Effective Prompt Engineering**  
   Explore state-of-the-art generative AI platforms and learn how to craft prompts for optimal outcomes.

---

## 3. Scope of Work (SoW)

### Task 1: Integrate GitHub Copilot and Visual Studio Code

**Description**  
- Explore how GitHub Copilot can assist in code generation and optimization within Visual Studio Code (VSC).  
- Practice writing clear code comments and function docstrings to improve Copilot suggestions.

**Key Activities**  
1. Set up Visual Studio Code and GitHub Copilot.  
2. Experiment with various code-writing scenarios (e.g., Python scripts, JavaScript functions).  
3. Document best practices for prompt writing in comments.  
4. Compare Copilot’s output with manually written code for efficiency and accuracy.

**Deliverables**  
- Sample code snippets showcasing Copilot-assisted development.  
- A short guide detailing tips and lessons learned about optimal Copilot usage.

**Estimated Timeline**  
- 1–2 weeks.

---

### Task 2: OpenAI API Development

**Description**  
- Learn how to integrate OpenAI’s API into simple applications.  
- Focus on sending queries to an LLM (Large Language Model) and processing its responses for a defined use case (e.g., Q&A, summarization).

**Key Activities**  
1. Obtain and manage API credentials securely.  
2. Write a simple Python or JavaScript script to send requests and handle responses from an OpenAI model.  
3. Experiment with different parameters (temperature, max\_tokens) to see how outputs change.  
4. Document usage patterns and constraints (rate limits, cost considerations).

**Deliverables**  
- A minimal application or script that demonstrates a basic AI-powered feature.  
- Written notes or a brief presentation explaining API interactions and best practices.

**Estimated Timeline**  
- 2–3 weeks.

---

### Task 3: Exploration of Generative AI Assets and Prompt Engineering

**Description**  
- Investigate various generative AI platforms (e.g., ChatGPT, Bard, Midjourney, DALL·E, Stable Diffusion) to understand how prompts influence outputs.  
- Develop an understanding of prompt engineering techniques (role prompts, persona, context framing).

**Key Activities**  
1. Compare multiple generative AI tools for text, image, or code generation.  
2. Document prompt structures that yield consistently high-quality or novel outputs.  
3. Conduct small experiments (e.g., generating short stories, step-by-step explanations, or images).  
4. Summarize findings in a “prompt engineering best practices” guide.

**Deliverables**  
- A mini “Prompt Engineering Handbook” showcasing different prompt styles and their effects.  
- Example outputs demonstrating successful and failed prompts.

**Estimated Timeline**  
- 2–3 weeks.

---

### Task 4: Build and Train a Simple Machine Learning Model

**Description**  
- Learn the basics of data preprocessing, feature engineering, model selection, and evaluation using libraries like scikit-learn and pandas.  
- Use a small, publicly available dataset (e.g., Iris, MNIST, or a Kaggle CSV such as `some\_data.csv`).

**Key Activities**  
1. Data cleaning and exploration.  
2. Model training (e.g., Logistic Regression, SVM, or Decision Tree).  
3. Performance evaluation using metrics (accuracy, precision, recall).  
4. Documentation of the entire ML pipeline (possibly in a Jupyter Notebook).

**Deliverables**  
- A well-commented codebase demonstrating the ML workflow.  
- A brief report or Notebook discussing results and insights.

**Estimated Timeline**  
- 2–3 weeks.

---

### Task 5: Create an AI Chatbot With Rasa or Dialogflow

**Description**  
- Develop a simple conversational agent to understand NLP-driven chatbot functionalities.  
- Emphasize intent classification, entity extraction, and conversation flow design.

**Key Activities**  
1. Define intents, entities, and dialogues.  
2. Implement basic NLU (Natural Language Understanding) with Rasa or Dialogflow.  
3. Test the chatbot and refine conversation logic.  
4. Deploy locally or via a free-tier cloud service for demonstration.

**Deliverables**  
- A working chatbot that handles predefined queries.  
- Documentation detailing intent/response mapping and NLP design.

**Estimated Timeline**  
- 2–4 weeks.

---

### Task 6: Explore AI for Creative Generative Art or Music

**Description**  
- Investigate how generative models (GANs, VAEs, or RNNs/transformers) create novel images or music.  
- Use frameworks such as TensorFlow, PyTorch, or Magenta.

**Key Activities**  
1. Review core concepts of generative modeling.  
2. Gather or prepare a dataset (images or MIDI files).  
3. Train a simple model and generate creative outputs.  
4. Evaluate outputs and discuss improvements or limitations.

**Deliverables**  
- A small gallery of generated art or short music clips.  
- Written summary or presentation on model architecture and outcomes.

**Estimated Timeline**  
- 3–4 weeks.

---

### Task 7: Develop a Simple Reinforcement Learning Environment

**Description**  
- Create or utilize an existing environment (e.g., OpenAI Gym) to understand the basics of reinforcement learning (RL).  
- Focus on agent-environment interaction, rewards, and policy optimization.

**Key Activities**  
1. Introduction to RL algorithms (Q-learning or Deep Q-Network).  
2. Select or design a simple environment (grid world, CartPole, etc.).  
3. Implement the RL agent and tweak hyperparameters to improve learning.  
4. Record performance metrics (reward vs. time, success rate).

**Deliverables**  
- A demo environment and agent code.  
- Plots/graphs showing training progression and final performance.

**Estimated Timeline**  
- 3–5 weeks.

---

### Task 8: AI Fairness and Bias Assessment Project

**Description**  
- Understand how bias can appear in AI models and learn techniques for detecting and mitigating it.  
- Use a dataset known to have demographic or other biases (e.g., UCI\_Adult dataset).

**Key Activities**  
1. Research fairness metrics (demographic parity, equalized odds).  
2. Implement or use fairness toolkits (e.g., IBM’s AI Fairness 360, Fairlearn).  
3. Assess model bias and apply a mitigation strategy (re-sampling, algorithmic fairness).  
4. Document findings and discuss ethical implications.

**Deliverables**  
- An experimental report highlighting detection and reduction of biases.  
- Code and documentation explaining the fairness analysis process.

**Estimated Timeline**  
- 3–4 weeks.

---

## 4. Methodology and Collaboration

- **Research & Learning**  
  Students review tutorials, documentation, and relevant literature for each task.  
- **Implementation**  
  Hands-on coding, experimentation, and testing form the core of each task.  
- **Validation**  
  Regular check-ins with mentors or peers to assess progress, troubleshoot issues, and refine approaches.  
- **Documentation**  
  Maintain clear notes, commit messages, code comments, and short project summaries for each completed task.

---

## 5. Milestones & Deliverables

1. **Task Kickoffs**  
   - Each task begins with a brief proposal outlining objectives, datasets, tools, and success criteria.  

2. **Mid-Task Reviews**  
   - Students share interim prototypes or findings for feedback and adjustments.  

3. **Final Presentations (per Task)**  
   - Each completed task ends with a presentation or demo (live or recorded).  

4. **Consolidated Report**  
   - At the conclusion of all tasks, compile a single overview document summarizing key learnings, successes, and future directions.

---

## 6. Roles and Responsibilities

- **Student Researcher (e.g., Kevin Olivares)**  
  Implements each task, experiments with tools, documents findings, and presents results.  
- **Faculty Advisor / Mentor**  
  Provides guidance, resources, and technical expertise; conducts reviews and offers feedback.  
- **Peer Collaborators (Optional)**  
  Participate in code reviews, share knowledge, and assist in problem-solving if tasks are done collaboratively.

---

## 7. Estimated Timeline (Conceptual)

| **Phase**                                 | **Duration**     | **Activities**                                                              |
|-------------------------------------------|------------------|-----------------------------------------------------------------------------|
| **Onboarding & Environment Setup**        | 1–2 weeks       | Tool installations, GitHub Copilot/VSC setup, obtaining API keys            |
| **Task 1: GitHub Copilot + VSC**          | 1–2 weeks       | Experimenting with Copilot-assisted coding                                  |
| **Task 2: OpenAI API Development**        | 2–3 weeks       | Simple app development using OpenAI API                                     |
| **Task 3: Generative AI & Prompt Engineering** | 2–3 weeks   | Comparing platforms, crafting effective prompts                             |
| **Task 4: Basic ML Model**                | 2–3 weeks       | Data cleaning, model training, evaluation                                   |
| **Task 5: AI Chatbot**                    | 2–4 weeks       | Conversational design, intent/entity setup, deployment                      |
| **Task 6: Generative Art/Music**          | 3–4 weeks       | Model training, creative output generation                                  |
| **Task 7: Reinforcement Learning**        | 3–5 weeks       | RL environment setup, agent training, performance monitoring                |
| **Task 8: AI Fairness & Bias**            | 3–4 weeks       | Implementing fairness metrics, mitigating bias                              |
| **Consolidation & Final Presentation**    | 1–2 weeks       | Collate findings, finalize documentation, present comprehensive overview    |

> **Note**: Some tasks may overlap depending on resources and individual pacing.

---

## 8. Success Criteria

- **Technical Mastery**  
  Demonstrated ability to use relevant tools (VSC, Copilot, OpenAI API) and ML frameworks (scikit-learn, PyTorch, TensorFlow, Rasa, etc.).

- **Depth of Analysis**  
  Quality of experimentation, interpretation of results, and overall understanding of AI concepts.

- **Documentation & Communication**  
  Clarity and completeness of written reports, code comments, and presentations.

- **Innovation & Creativity**  
  Novel approaches to generative tasks and RL environments; effective prompt engineering strategies.

- **Ethical Awareness**  
  Ability to identify, analyze, and address AI bias; articulate ethical considerations of AI applications.

---

## 9. Conclusion

By pursuing these **eight distinct tasks**, students—particularly incoming Computer Science freshmen—will gain a **broad yet practical** education in AI. From leveraging modern coding assistants (GitHub Copilot) to developing their own ML models, chatbots, generative art, and responsible AI frameworks, the progression offers a **holistic experience**. This SoW ensures that each task builds on core skills while expanding the student’s expertise across various domains of AI, ultimately cultivating capable and conscientious AI practitioners.
