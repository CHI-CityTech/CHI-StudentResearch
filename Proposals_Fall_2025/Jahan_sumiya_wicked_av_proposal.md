
# Trust and Transparency in Smart Mobility Systems:  
## Ethical AI, Cybersecurity, and Mediation in Blended Environments.

**Student Researcher:** Sumiya Jahan
**Mentor:** Dr. David B. Smith
**Program:** Federal Work-Study (FWS) / Emerging Scholars Program

**Parent Framework:** [CASTI–Mobility Sub-Project](https://github.com/CHI-CityTech/CHI-StudentResearch/blob/main/Potential%20Projects/casti_mobility_subproject.md)  
**Meta-Project Context:** [CHI Autonomous Systems Trust Initiative (CASTI) Meta-Project](https://github.com/CHI-CityTech/CHI-StudentResearch/blob/main/Potential%20Projects/casti_meta_project_framework.md) 

This proposal functions as a **subset investigation** within the CASTI–Mobility Sub-Project. It focuses on the specific question of **public trust in autonomous transportation systems**, serving as an initial, literature-driven and speculative research phase that will contribute foundational analysis and BBS syntax models to CASTI’s broader framework of trust, ethics, safety, and reliability in autonomous control environments.

**Title:** Trust and Transparency in Smart Mobility Systems: Ethical AI, Cybersecurity, and Mediation in Blended Environments

---

### Statement of Work (SoW)

#### 1. Overview

This research proposal, conducted under the aegis of the **Center for Holistic Integration (CHI)**, investigates how public trust in autonomous mobility systems can be built through ethical AI design, robust cybersecurity, and transparent communication within **Balanced Blended Space (BBS)**. The project acknowledges that autonomous mobility—where AI systems interact with the physical environment and human society—is not only a technical challenge but also an ethical and social negotiation. It therefore treats the study of AI-human trust as both a descriptive inquiry and a design exercise in conceptual modeling rather than direct implementation.

The primary emphasis of this phase is **research and speculation**, not the development of a full simulation. While the project will describe the **conceptual design of a test environment** that could later explore these ideas in practice, the immediate goal is to consolidate existing knowledge, propose a framework for trust mediation, and generate recommendations for future CASTI–Mobility experimental work.

#### 2. Objectives

1. **Map Ethical and Technical Dependencies:** Identify how cybersecurity, AI ethics, and transparency interrelate in smart mobility systems.
2. **Model Trust Pathways:** Define how trust is established, maintained, and lost between humans and AI agents.
3. **Develop a Syntactical Framework:** Use the **BBS syntax** to formalize how signals of trust and mediation flow between cognitive and computational intelligences.
4. **Conceptualize a Test Environment:** Propose the architecture and research parameters for a potential future simulation that could safely investigate ethical and technical interactions.
5. **Cross-Meta-Project Integration:** Extend findings to other CHI initiatives—particularly drone systems and smart infrastructure—to develop generalizable methods of ethical mediation.

#### 3. Methodology

The project will follow CHI’s five-stage meta-project structure—**Research, Design, Produce, Publish, Assess**—adapted for a limited FWS timescale emphasizing research, synthesis, and conceptual design.

**Research Phase:** Conduct an extensive literature review of ethical AI, cybersecurity in smart mobility, and public trust frameworks. This review will not be limited to New York City, Singapore, or Helsinki but will also examine major international deployments and pilot programs, including fully autonomous taxi operations in **San Francisco, Phoenix, Shenzhen, and Tokyo**. The goal is to understand how public expectations of trust differ across regions and how these expectations intersect with ethical and safety standards.

**Design Phase:** Develop conceptual models of trust communication and mediation within BBS, producing **syntax diagrams and trust flow maps** to describe how intent, data, and interpretation move between human and machine agents. The design will include a conceptual proposal for a **risk-tolerant test environment**, identifying what elements would need to be simulated and what data might be collected.

**Publication Phase:** Document findings in the CHIIDS repository, producing open-access materials (BBS diagrams, trust models, and literature summaries) for integration into the CASTI–Mobility dataset.

**Assessment Phase:** Evaluate the work for clarity, completeness, and contribution to CASTI–Mobility, focusing on its potential to inform later ethical and technical investigations.

#### 4. Deliverables and Effort

This project operates under a **Federal Work-Study (FWS)** appointment, requiring approximately **8–10 hours per week** over the semester. Given this limited scope, deliverables emphasize conceptual and analytical output.

**Primary Deliverables:**

1. **Research Paper (Final Report):** A synthesis of findings on trust, transparency, and ethical mediation in autonomous mobility systems, with recommendations for future CASTI–Mobility phases.
2. **Poster Presentation:** A concise visual summary of trust frameworks, BBS syntax models, and ethical considerations for CHI or City Tech presentations.
3. **Conceptual Test Environment Proposal:** A design outline for how a simulation could model trust, accountability, and decision transparency without physical testing.
4. **BBS Syntax Mapping:** A set of diagrams that describe mediation and communication pathways between human and computational agents.
5. **Reflection Log:** Weekly entries documenting progress, research insights, and reflections for CHIIDS archival inclusion.

#### 5. Integration with CASTI–Mobility and Future Research

The results of this study will provide **theoretical groundwork and preliminary models** for the **CASTI–Mobility Sub-Project**. Data from the literature review and BBS mapping will inform future CASTI–Mobility efforts to design simulation scenarios and test ethical frameworks.

Specifically, this project will:

* Contribute to CASTI–Mobility’s database of trust-related literature and comparative studies.
* Supply initial syntax diagrams and conceptual models for trust mediation.
* Provide recommendations for building a safe, risk-tolerant test environment in future phases.
* Support CHI’s continuing research into **reciprocal trust** between humans and autonomous systems through an ethical and theoretical lens.

As an **Emerging Scholars / FWS project**, this work serves as a catalyst rather than a conclusive study—laying the intellectual and structural foundation upon which later CASTI–Mobility projects can build simulation prototypes, ethical mediation models, and applied trust analytics.
